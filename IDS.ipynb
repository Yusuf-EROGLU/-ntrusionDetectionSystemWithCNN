{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Importing the data into pandas DataFrames separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monday = pd.read_csv(r\"\\MachineLearningCVE\\Monday-WorkingHours.pcap_ISCX.csv\", low_memory=False)\n",
    "tuesday = pd.read_csv(r\"\\MachineLearningCVE\\Tuesday-WorkingHours.pcap_ISCX.csv\", low_memory=False)\n",
    "wednesday = pd.read_csv(r\"\\MachineLearningCVE\\Wednesday-workingHours.pcap_ISCX.csv\", low_memory=False)\n",
    "thursdayMorning = pd.read_csv(r\"\\MachineLearningCVE\\Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\", low_memory=False)\n",
    "thursdayAfternoon = pd.read_csv(r\"\\MachineLearningCVE\\Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\", low_memory=False)\n",
    "fridayMorning = pd.read_csv(r\"\\MachineLearningCVE\\Friday-WorkingHours-Morning.pcap_ISCX.csv\", low_memory=False)\n",
    "fridayAfternoonPortscan = pd.read_csv(r\"\\MachineLearningCVE\\Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\", low_memory=False)\n",
    "fridayAfternoonDDos = pd.read_csv(r\"\\MachineLearningCVE\\Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Combining DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([monday, tuesday, wednesday, thursdayMorning, thursdayAfternoon, fridayMorning, fridayAfternoonPortscan, fridayAfternoonDDos], axis =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Checking the line numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monday.shape[0] + tuesday.shape[0] + wednesday.shape[0] + thursdayAfternoon.shape[0] + thursdayMorning.shape[0] + fridayMorning.shape[0] + fridayAfternoonPortscan.shape[0] + fridayAfternoonDDos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Descriptive statistics summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasetSummary.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset.columns)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Number of lines with 'Infinity' and 'NaN' values of 'Flow Packets / s' feature\n",
    "> If the number of rows is not too high (<% 1), missing data will be removed in preprocessing. \n",
    "> Pre-processing part of the article was used. https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8804816&tag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.loc[dataset[' Flow Packets/s'] == 'Infinity'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset[' Flow Packets/s']== 'NaN'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv1 = dataset.loc[dataset[' Flow Packets/s'] != 'Infinity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### This article uses min-max Normalization. \n",
    "> #### The **entity embedding technique** was used to use categorical data in DNN. https://arxiv.org/pdf/1910.02203.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### \"*Source IP, Destination IP, Source Port, Destination Port*\" features are categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Entity embedding whitepaper -> https://arxiv.org/pdf/1604.06737v1.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Listing of single values with attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dataset.columns:\n",
    "    if datasetv1[col].nunique() < 2:\n",
    "        print(col , datasetv1[col].nunique())\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### İlgili çalışmada veri seti olarak 'TrafficLabelling' olarak hazırlanmış veri seti kullanılmış. Bu veri seti içerisinde nitelik olarak Source IP ve Destination IP gibi değerler bulunmaktadır. Bu değerler veri toplama esnasında kurulan sentetik ortamın niteliklerini yansıtacağı bu sebeple kullanılan veri seti üzerinde yüksek doğruluk verirken farklı bir networkde detection'a bir katkı sağlamayacağı varsayımı doğrultusunda çalışmada Machine Learning için özelleştirilmiş olan veri seti dosyası kullanılmıştır.(https://arxiv.org/pdf/1910.02203.pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### TrafficLabelling formatındaki veri seti için yukarıda belirtilen çalışmada kullanılan \"Source IP, Destination IP, Source Port, Protocol\" gibi featureların kullanımının yanlış olduğunun gösterimesi:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Dropping single value features in Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv2 = datasetv1.copy()\n",
    "# where the column names for the for loop are pre-assigned, they can be returned to the loop as col value in the dropped column labels, so an error is received.\n",
    "for col in datasetv2.columns:\n",
    "    if datasetv2[col].nunique() == 1:\n",
    "        datasetv2.drop([col], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datasetv1.columns), len(datasetv2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### z-score normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Column typeların sayısal değer olması gerekiyor. \n",
    "for col in datasetv2.columns:\n",
    "    print(col,'      ',datasetv2[col].dtypes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# column types converted to float64.\n",
    "datasetv3 = datasetv2.copy()\n",
    "count = 0\n",
    "for col in datasetv3:\n",
    "    if col != ' Label':\n",
    "        datasetv3[col] = datasetv3[col].astype('float64')\n",
    "        count= count +1\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in datasetv3.columns:\n",
    "    print(col,'      ',datasetv3[col].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats  import zscore\n",
    "#stats.zscore(datasetv3.loc[:, datasetv3.columns != ' Label'], axis=1)\n",
    "numeric_cols = datasetv3.select_dtypes(include=[np.number]).columns\n",
    "datasetv4 = datasetv3[numeric_cols].apply(zscore).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv4[' Label'] = datasetv3[' Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Converting the values in the label column to numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv4[' Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv4[' Label'].replace(datasetv4[' Label'].unique(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 , 12, 13, 14], inplace = True)\n",
    "datasetv4[' Label'].unique()\n",
    "datasetv4[' Label'] = datasetv4[' Label'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Columns have been changed because the spaces in column name are troublesome in Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datasetv4.columns:\n",
    "    datasetv4.rename(columns = {col : col.strip().replace(' ','_')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetv4.head()\n",
    "#datasetv4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(datasetv4, test_size=0.2)\n",
    "\n",
    "print(len(train), 'train examples')\n",
    "print(len(test), 'test examples')\n",
    "print(len(datasetv4), 'total')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train.copy()\n",
    "train_label = train_set.pop('Label')\n",
    "train_label_binary = train_label.copy()\n",
    "train_label_binary.replace(range(1,15),1, inplace = True)\n",
    "\n",
    "\n",
    "test_set = test.copy()\n",
    "test_label = test_set.pop('Label')\n",
    "test_label_binary = test_label.copy()\n",
    "test_label_binary.replace(range(1,15), 1, inplace = True)\n",
    "\n",
    "train_set = train_set.to_numpy().reshape(2262300, 70, 1)\n",
    "train_label = train_label.to_numpy()\n",
    "train_label_binary = train_label_binary.to_numpy()\n",
    "\n",
    "\n",
    "test_set = test_set.to_numpy().reshape(565576, 70, 1)\n",
    "test_label = test_label.to_numpy()\n",
    "test_label_binary = test_label_binary.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test_label_binary = to_categorical(test_label_binary)\n",
    "#train_label_binary = to_categorical(train_label_binary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Multi-class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv1D(16, (2), activation='relu', input_shape=(70, 1)),\n",
    "  tf.keras.layers.MaxPooling1D(2),\n",
    "  tf.keras.layers.Conv1D(16, (2), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling1D(2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(15, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(train_set, train_label, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(test_set)\n",
    "con_mat = tf.math.confusion_matrix(labels = test_label, predictions = y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "con_mat_df = pd.DataFrame(con_mat_norm)\n",
    "con_mat_df.columns = datasetv3[' Label'].unique()\n",
    "con_mat_df.index = datasetv3[' Label'].unique()\n",
    "con_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels ekleecek https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "print(precision_recall_fscore_support(test_label_binary, y_pred, average='macro'))\n",
    "\n",
    "print(precision_recall_fscore_support(test_label_binary, y_pred, average='micro'))\n",
    "\n",
    "print(precision_recall_fscore_support(test_label_binary, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Binary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelv2 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv1D(16, (2), activation='relu', input_shape=(70, 1)),\n",
    "  tf.keras.layers.MaxPooling1D(2),\n",
    "  tf.keras.layers.Conv1D(16, (2), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling1D(2),\n",
    "  tf.keras.layers.Flatten(),\n",
    " # tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modelv2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "modelv2.summary()\n",
    "modelv2.fit(train_set, train_label_binary, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_lossv2 = modelv2.evaluate(test_set, test_label_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predv2 = modelv2.predict_classes(test_set)\n",
    "con_matv2 = tf.math.confusion_matrix(labels = test_label_binary, predictions = y_predv2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(precision_recall_fscore_support(test_label_binary, y_predv2, average='macro'))\n",
    "\n",
    "print(precision_recall_fscore_support(test_label_binary, y_predv2, average='micro'))\n",
    "\n",
    "print(precision_recall_fscore_support(test_label_binary, y_predv2, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_normv2 = np.around(con_matv2.astype('float') / con_matv2.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "con_mat_dfv2 = pd.DataFrame(con_mat_normv2)\n",
    "con_mat_dfv2.columns = ['Negative', 'Positive']\n",
    "con_mat_dfv2.index = ['Negative', 'Positive']\n",
    "con_mat_dfv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(con_mat_dfv2, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
